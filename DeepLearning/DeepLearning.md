# Deep Learning

## 机器学习基础

表示学习：为了提高机器学习系统的准确率，我们就需要将输入信息转换为有效的特征，或者更一般性地成为表示。如果一种算法可以自动地学习出有效的特征，并提高最终机器学习模型的性能，那么这种学习就可以叫做表示学习。

深度学习是具有多个表示级别的表示学习方法，通过组合简单但非线性的模块获得，每个模块将一个级别的表示（从原始输入开始）转换为更高、更抽象的表示。

神经网络和深度学习不等价。

## 深度学习模型分类

| 网络结构                 | 特点                                                         | 使用场景                                    |
| ------------------------ | ------------------------------------------------------------ | ------------------------------------------- |
| 多层感知机（前馈网络）   | 相邻两层的神经元之间为全连接关系，具有很强的拟合能力，常见的连续非线性函数都可以用前馈网络来近似 | 最简单的网络                                |
| 卷积神经网络（前馈网络） | MLP参数过多，无法提取局部不变性特征；局部连接、权重共享、汇聚 | CV，输入和输出维数固定                      |
| 循环神经网络，LSTM       | 具有短期记忆功能，可以近似任何一个非线性动力系统，但会出现梯度消失/爆炸现象 | 处理时序数据                                |
| 图神经网络               | -                                                            |                                             |
| 自编码器AE，VAE          | 深度生成模型（无监督），f: R^D -> R^M, g: R^M -> R^D，最小化重构错误 | M<D，降维、特征提取；M>=D，稀疏性、取值范围 |
| 深度信念网络DBN          | 深度生成模型，生成符合特定分布的样本；采用逐层预训练和精调   | 学习数据的内部特征表示；降维                |
| GAN                      | 深度生成模型，生成符合数据分布的样本，不显示地估计出数据分布的密度函数；一个判别网络，一个生成网络，对抗训练 | 图像生成                                    |
| 深度强化学习DQN          | -                                                            |                                             |
| 序列生成模型Transformer  |                                                              | CV，NLP等                                   |

## 学习方式

- 对比学习
- 多模态学习